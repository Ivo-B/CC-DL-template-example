{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143199cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MNIST handwritten digits dataset.\n",
    "This is a dataset of 60,000 28x28 grayscale images of the 10 digits,\n",
    "along with a test set of 10,000 images.\n",
    "More info can be found at the\n",
    "[MNIST homepage](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "License:\n",
    "    Yann LeCun and Corinna Cortes hold the copyright of MNIST dataset,\n",
    "    which is a derivative work from original NIST datasets.\n",
    "    MNIST dataset is made available under the terms of the\n",
    "    [Creative Commons Attribution-Share Alike 3.0 license.](\n",
    "    https://creativecommons.org/licenses/by-sa/3.0/)\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import numpy as np\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "# find .env automagically by walking up directories until it's found, then\n",
    "# load up the .env entries as environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "path = Path(os.environ.get('PROJECT_DIR')) / 'data' / 'raw'\n",
    "\n",
    "origin_folder = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/'\n",
    "path_download = get_file(\n",
    "  path / 'mnist.npz',\n",
    "  origin=origin_folder + 'mnist.npz',\n",
    "  file_hash=\n",
    "  '731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c1057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(path_download, allow_pickle=True) as f:  # pylint: disable=unexpected-keyword-arg\n",
    "    x_train, y_train = f['x_train'], f['y_train']\n",
    "    x_test, y_test = f['x_test'], f['y_test']\n",
    "\n",
    "all_x = np.concatenate((x_train, x_test))\n",
    "all_y = np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600ee0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x = all_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45ef6ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.environ.get('PROJECT_DIR')) / 'data' / 'processed'\n",
    "\n",
    "for idx in range(len(all_x)):\n",
    "    np.save(path / f'{idx:05d}', all_x[idx,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65aadd89",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(all_x, all_y, test_size=10000, random_state=42, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "path = Path(os.environ.get('PROJECT_DIR')) / 'data'\n",
    "\n",
    "with open(path / 'test_data.txt', 'a') as f:\n",
    "    for name, x, y in zip(list(range(60000, 70000)), X_test, y_test):\n",
    "        assert np.all(all_x[name] == x) == True\n",
    "        f.write(f\"{name:05d}.npy, {y}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=5000, random_state=42, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "with open(path / 'training_data.txt', 'a') as f:\n",
    "    for name, x, y in zip(list(range(0, 55000)), X_train, y_train):\n",
    "        assert np.all(all_x[name] == x) == True\n",
    "        f.write(f\"{name:05d}.npy, {y}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "with open(path / 'validation_data.txt', 'a') as f:\n",
    "    for name, x, y in zip(list(range(55000, 60000)), X_val, y_val):\n",
    "        assert np.all(all_x[name] == x) == True\n",
    "        f.write(f\"{name:05d}.npy, {y}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}